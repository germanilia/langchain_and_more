{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "kl5IozbEhtDF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.27.9 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (0.27.9)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from openai==0.27.9) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from openai==0.27.9) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from openai==0.27.9) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.9) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.9) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.9) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests>=2.20->openai==0.27.9) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp->openai==0.27.9) (1.3.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: langchain==0.0.274 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (0.0.274)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (3.8.5)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (0.0.26)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from langchain==0.0.274) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.274) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.274) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.274) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.274) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.274) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.274) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.274) (1.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: huggingface_hub in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.27.9\n",
        "!pip install langchain==0.0.274\n",
        "!pip install huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "D28h1V9As5dk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "0tSEZWrntTaG"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm=ChatOpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "3mstKj5GtkSA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Title: \"The Legacy of Sheer Driving Pleasure\"\\n\\nOnce upon a time in Munich, Germany, in 1916, an aircraft engine manufacturer named \"Bayerische Flugzeugwerke\" was born. After World War I, the company was forced to cease aircraft production, due to the terms of the Treaty of Versailles. They had to switch gears and found a new path, leading them into the realm of automobiles.\\n\\nIn 1928, they produced their first car, the \"Dixi\"; it was a modest but reliable vehicle. However, the company, now known as BMW (Bayerische Motoren Werke), desired to create something more, something better. They wanted to engineer a machine that would not only transport people from one place to another but would also provide a unique driving experience.\\n\\nThe 1930s saw BMW establishing its reputation for creating high-end, luxury vehicles with the release of the BMW 303. This was the first car to feature the now-iconic kidney grille, a design element that is synonymous with BMW today.\\n\\nThe years that followed were challenging due to World War II, but BMW persisted. In 1959, the company was on the brink of bankruptcy and a takeover by Daimler-Benz was imminent. However, shareholders and workers rallied together and fought to keep the company independent. Their efforts were successful, and BMW managed to survive.\\n\\nIn the 1970s, BMW launched the 3 Series, which became their best-selling model and solidified BMW\\'s reputation as a maker of sporty, driver-focused cars. The tagline \"The Ultimate Driving Machine\" was born, encapsulating the company\\'s dedication to crafting vehicles that offered superior performance and driving pleasure.\\n\\nFast forward to the present day, BMW is now a global brand, renowned for its combination of luxury and performance. It has expanded its range to include electric vehicles with its \"i\" series, showing the world its commitment to sustainable mobility while keeping to its promise of sheer driving pleasure.\\n\\nBMW\\'s story is one of resilience, innovation, and an unwavering commitment to quality. Despite the trials and tribulations, BMW has always stayed true to its vision, and it continues to create vehicles that embody the joy of driving.' additional_kwargs={} example=False\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Tell me a short story about BMW\"\n",
        "print(llm.invoke(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "vDkTxWRBuTN8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flan-t5-xxl: south africa\n",
            "flan-t5-large: argentina\n"
          ]
        }
      ],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\": 0.7})\n",
        "print(f\"flan-t5-xxl: {llm('Who won the FIFA World Cup in the year 1994? ')}\")\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\": 0.7})\n",
        "print(f\"flan-t5-large: {llm('Who won the FIFA World Cup in the year 1994? ')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsH7DyFWv2eV"
      },
      "source": [
        "**Prompt templates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "NUGIezsRv7p_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I want to write a new lecture about Cars, suggest a fancy name for this\n",
            "content='\"Automotive Evolution: The Journey from Horsepower to Hypercars\"' additional_kwargs={} example=False\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_lecture_name = PromptTemplate(\n",
        "    input_variables=[\"subject\"],\n",
        "    template=\"I want to write a new lecture about {subject}, suggest a fancy name for this\"\n",
        ")\n",
        "\n",
        "text = prompt_template_lecture_name.format(subject=\"Cars\")\n",
        "print(text)\n",
        "print(llm.invoke(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "6SAHrEOXxLzr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "local:  First, we need to identify the country that hosted the FIFA World Cup in 1994. The FIFA World Cup was held in the United States in 1994.\n",
            "\n",
            "Next, we need to figure out which teams participated in the tournament. A total of 32 teams from various regions of the world qualified for the 1994 FIFA World Cup.\n",
            "\n",
            "The final match of the 1994 FIFA World Cup was played between Brazil and Germany on July 17, 1994, at the Rose Bowl in Pasadena, California. Brazil won the match with a score of 2-0, claiming their fourth World Cup title.\n",
            "\n",
            "Therefore, the answer is that Brazil won the FIFA World Cup in 1994.\n"
          ]
        }
      ],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "repo_id=\"google/flan-t5-large\"\n",
        "# llm = HuggingFaceHub(\n",
        "#     repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        "# )\n",
        "# prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "# print(f\"flan-t5-large: {llm_chain.run('Who won the FIFA World Cup in the year 1994? ')}\")\n",
        "\n",
        "llm=ChatOpenAI(openai_api_base=\"http://localhost:1234/v1\", max_tokens=5000)\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "print(f\"local: {llm_chain.run('Who won the FIFA World Cup in the year 1994? ')}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "qA2cTFzlyUzV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to write a new lecture about Pizza, suggest a fancy name for this\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest some topics for this lecture: \"The Art and Science of Pizza: A Culinary Journey\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "1. History of Pizza: From Italy to the World\n",
            "2. The Science Behind the Perfect Pizza Dough\n",
            "3. Understanding the Chemistry of Baking\n",
            "4. The Art of Pizza Topping Arrangement\n",
            "5. The Influence of Oven Types and Baking Techniques \n",
            "6. Nutritional Analysis of Pizza Ingredients\n",
            "7. Traditional vs. Modern Pizza: Differences and Similarities \n",
            "8. The Role of Fermentation in Pizza Making\n",
            "9. Pizza and Culture: Regional Variations across Italy\n",
            "10. Pizza Pairings: The Science of Complementing Flavors\n",
            "11. Pizza in Popular Culture: Movies, Music, and More\n",
            "12. The Psychology of Pizza: Why is it So Universally Loved?\n",
            "13. Exploring Unique Pizza Styles Around the Globe\n",
            "14. The Art of Pizza Spinning \n",
            "15. Evolution of Pizza: From Simple Beginnings to Gourmet Creations \n",
            "16. Innovations in Pizza Making: From Wood-fired Ovens to High-tech Equipment\n",
            "17. Experimenting with Pizza: Unconventional Ingredients and Recipes\n",
            "18. The Pizza Economy: A Look into the Business Side \n",
            "19. How Climate and Geography Affect Pizza Ingredients\n",
            "20. The Role of Pizza in Sustainable Food Practices.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "\n",
        "# 1\n",
        "prompt_template_lecture_name = PromptTemplate(\n",
        "    input_variables=[\"subject\"],\n",
        "    template=\"I want to write a new lecture about {subject}, suggest a fancy name for this\",\n",
        ")\n",
        "\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt_template_lecture_name, verbose=True)\n",
        "\n",
        "\n",
        "# 2\n",
        "prompt_template_topics = PromptTemplate(\n",
        "    input_variables=[\"title\"], template=\"Suggest some topics for this lecture: {title}\"\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(llm=llm, prompt=prompt_template_topics, verbose=True)\n",
        "\n",
        "# seq chain\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "schain = SimpleSequentialChain(chains=[chain1, chain2])\n",
        "\n",
        "final_response = schain.run(\"Pizza\")\n",
        "\n",
        "print(final_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "eXOQAxyt06I9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'subject': 'Space',\n",
              " 'movie_name': ' Sure! Here are some great movies that take place in space or feature space-related themes:\\n\\n1. \"The Imitation Game\" (2014) - This movie tells the story of Alan Turing and his team during World War II as they worked to crack the Enigma code used by the German military. The film includes scenes set in space, as well as themes of science and technology.\\n2. \"The Martian\" (2015) - Based on the novel by Andy Weir, this movie follows astronaut Mark Watney as he struggles to survive alone on Mars after being left behind by his crew during a mission. The film includes stunning visuals of space and is full of scientific details about the challenges of space travel.\\n3. \"Interstellar\" (2014) - This sci-fi drama follows a team of astronauts as they travel through a wormhole in search of a new home for humanity, which has been devastated by climate change and other disasters. The film includes stunning visuals of space and explores complex themes of time, fate, and the nature of existence.\\n4. \"Apollo 13\" (1995) - This historical drama tells the true story of the Apollo 13 mission, which was aborted after an explosion on board the spacecraft threatened the lives of all aboard. The film includes intense scenes of space travel and explores themes of leadership, teamwork, and survival.\\n5. \"Gravity\" (2013) - This thrilling sci-fi drama follows astronaut Ryan Stone as she struggles to survive in space after her spacecraft is destroyed during a mission. The film includes stunning visuals of space and explores themes of isolation, fear, and the will to live.\\n6. \"The Expanse\" (2016-present) - This sci-fi TV series is set in a future where Earth has been colonized by Mars and other planets. The show follows a diverse cast of characters as they navigate political intrigue, space battles, and other challenges in a complex and often dangerous universe.\\n7. \"E.T. the Extra Terrestrial\" (1982) - This classic sci-fi movie tells the story of young Elliott, who befriends an alien named E.T. during a time of political and social upheaval on Earth. The film includes iconic visual effects and explores themes of friendship, loss, and the power of imagination.\\n\\nI hope these recommendations help you find something great to watch!',\n",
              " 'plot': \" That's a fantastic list! I appreciate your effort in providing such detailed descriptions for each movie. It's clear that there are many great options available for people who are interested in space-related movies. Thank you for sharing your recommendations!\"}"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "\n",
        "# llm=ChatOpenAI(model=\"gpt-4\")\n",
        "llm=ChatOpenAI(openai_api_base=\"http://localhost:1234/v1\", max_tokens=5000)\n",
        "\n",
        "# 1\n",
        "prompt_template_movie_name = PromptTemplate(\n",
        "    input_variables=[\"subject\"],\n",
        "    template=\"I want to watch a movie on {subject},recommend me on some movies\"\n",
        ")\n",
        "\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt_template_movie_name, output_key=\"movie_name\")\n",
        "\n",
        "# 2\n",
        "prompt_template_movie_plot = PromptTemplate(\n",
        "    input_variables=[\"movie_name\"],\n",
        "    template=\"What is the plot for the movie {movie_name}?\"\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(llm=llm, prompt=prompt_template_movie_plot, output_key=\"plot\")\n",
        "\n",
        "schain = SequentialChain(\n",
        "    chains = [chain1, chain2],\n",
        "    input_variables = [\"subject\"],\n",
        "    output_variables = [\"movie_name\", \"plot\"],\n",
        ")\n",
        "\n",
        "schain(\"Space\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAg3tWM13NDN"
      },
      "source": [
        "**Agents and Tools**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "iMpLUX7y3ROm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-search-results in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->google-search-results) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->google-search-results) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->google-search-results) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests->google-search-results) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5QAx0TTa62vV"
      },
      "outputs": [],
      "source": [
        "os.environ['SERPAPI_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "lMjgw6tp7FQy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis question seems to be asking for the updated GDP of Israel in 2022 if we add 1 million USD to it. First, I need to find the GDP of Israel in 2022.\n",
            "Action: Search\n",
            "Action Input: \"Israel GDP 2022\" \u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m$522,033,000,000\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe GDP of Israel in 2022 is $522,033,000,000. Now I need to add 1 million USD to this.\n",
            "Action: Calculator\n",
            "Action Input: 522033000000 + 1000000\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 522034000000\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The updated GDP of Israel in 2022, with an additional 1 million USD, would be $522,034,000,000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The updated GDP of Israel in 2022, with an additional 1 million USD, would be $522,034,000,000.'"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# agent.run(\"Who won the World cup in 2022?\")\n",
        "# agent.run(\"What was the GDP of Israel in 2022 plus one million\")\n",
        "agent.run(\"Add 1M $ to israel GDP in 2022\")\n",
        "# agent.run(\"What are the latest news from Israel?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "n4Bx20CxBfuL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from wikipedia) (4.12.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=d659e0f5eda69343d3a5808386c88e677269f2046b2fe57c77f3a3c158781bc4\n",
            "  Stored in directory: /Users/iliagerman/Library/Caches/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "NY9_HDCCBX8S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find the biggest animal in the world.\n",
            "Action: Wikipedia\n",
            "Action Input: \"biggest animal in the world\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Largest and heaviest animals\n",
            "Summary: The largest animal currently alive is the blue whale. The maximum recorded weight was 190 tonnes for a specimen measuring 27.6 metres (91 ft), whereas longer ones, up to 33.6 metres (110 ft), have been recorded but not weighed. It is estimated, this individual could have a mass of 250 tonnes. The longest non-colonial animal is the lion's mane jellyfish (36.6m / 120 ft).In 2023, paleontologists estimated that the extinct whale Perucetus, discovered in Peru, may have outweighed the blue whale, with a mass of 85-340 t (84-335 long tons; 94-375 short tonnes). While controversial, estimates for the weight of the sauropod Bruhathkayosaurus suggest it was around 110-170 tons, with the highest estimate being 240 tons, if scaled with Patagotitan, although actual fossil remains no longer exist, and that estimation is based on described dimensions in 1987. The upper estimates of weight for these two prehistoric animals would have easily rivaled or exceeded the blue whale. \n",
            "The African bush elephant (Loxodonta africana) is the largest living land animal. A native of various open habitats in sub-Saharan Africa, males weigh about 6.0 tonnes (13,200 lb) on average. The largest elephant ever recorded was shot in Angola in 1974. It was a male measuring 10.67 metres (35.0 ft) from trunk to tail and 4.17 metres (13.7 ft) lying on its side in a projected line from the highest point of the shoulder, to the base of the forefoot, indicating a standing shoulder height of 3.96 metres (13.0 ft). This male had a computed weight of 10.4 tonnes.\n",
            "\n",
            "Page: Animal (2023 film)\n",
            "Summary: Animal is a 2023 Indian Hindi-language action drama film directed and edited by Sandeep Reddy Vanga, who also co-wrote the screenplay with Pranay Reddy Vanga and Saurabh Gupta. The film is produced by Bhushan Kumar, Pranay Reddy Vanga, Krishan Kumar and Murad Khetani under T-Series Films, Bhadrakali Pictures and Cine1 Studios. The film stars Ranbir Kapoor, Anil Kapoor, Bobby Deol, Rashmika Mandanna and Tripti Dimri. In the film, Ranvijay Singh, a violent young man, learns about an assassination attempt on his father and sets out to exact revenge.\n",
            "The film was officially announced in January 2021, along with the title of the film. Principal photography commenced in April 2022 and wrapped by April 2023. The film has music composed by JAM8, Vishal Mishra, Jaani, Manan Bhardwaj, Shreyas Puranik, Ashim Kemson and Harshwardhan Rameshwar. The cinematography was handled by Amit Roy and editing by Sandeep Reddy Vanga. With a runtime of 201 minutes, the film was one of the longest Indian films ever made.Animal was initially set for 11 August 2023 release but was postponed due to post-production work. It was theatrically released on 1 December 2023 in Hindi, Telugu, Tamil, Malayalam and Kannada languages in standard and IMAX formats. The film received generally mixed-to-negative reviews. It broke several box office records for a Hindi film, including the highest non-holiday opening, biggest single days, highest opening weekend and highest opening week in India. At the overseas box-office, it broke several records and eventually emerged as the highest-grossing Indian film in Australia and Canada. It grossed â‚¹904.93 crore (US$110 million) worldwide and emerged as a major commercial success becoming the third highest-grossing Indian film of 2023, the fifth-highest-grossing Hindi film, the ninth highest-grossing Indian film, and the highest-grossing A-rated Indian film. It also became the highest-grossing film of Kapoor's career, surpassing Sanju (2018).\n",
            "\n",
            "\n",
            "\n",
            "Page: List of animal sounds\n",
            "Summary: Certain words in the English language represent animal sounds: the noises and vocalizations of particular animals, especially noises used by animals for communication. The words can be used as verbs or interjections in addition to nouns, and many of them are also specifically onomatopoeic.\n",
            "\n",
            "\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "ename": "OutputParserException",
          "evalue": "Could not parse LLM output: `The biggest animal in the world is the blue whale, with a maximum recorded weight of 190 tonnes.`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[132], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# agent.run(\"Who won the World cup in 2022?\")\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho is the biggest animal is the world?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:475\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    476\u001b[0m         _output_key\n\u001b[1;32m    477\u001b[0m     ]\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    481\u001b[0m         _output_key\n\u001b[1;32m    482\u001b[0m     ]\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    283\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    284\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    286\u001b[0m )\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    270\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    271\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1036\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1036\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1045\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1046\u001b[0m         )\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:844\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    842\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    845\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:833\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    830\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 833\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:457\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    456\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/mrkl/output_parser.py:52\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     48\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: text\u001b[38;5;241m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()}, text\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[1;32m     55\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[1;32m     60\u001b[0m ):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[1;32m     64\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     65\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m     )\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `The biggest animal in the world is the blue whale, with a maximum recorded weight of 190 tonnes.`"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# agent.run(\"Who won the World cup in 2022?\")\n",
        "response = agent.run(\"Who is the biggest animal is the world?\")\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "ename": "OutputParserException",
          "evalue": "Could not parse LLM output: ` Who won the World cup in 2022?`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[133], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m llm\u001b[38;5;241m=\u001b[39mChatOpenAI(openai_api_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:1234/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTake a deep breath and think about this step-by-step. Who won the World cup in 2022?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# response = agent.run(\"Take a deep breath and think about this step-by-step. Who is the biggest animal is the world?\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:475\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    476\u001b[0m         _output_key\n\u001b[1;32m    477\u001b[0m     ]\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    481\u001b[0m         _output_key\n\u001b[1;32m    482\u001b[0m     ]\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    283\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    284\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    286\u001b[0m )\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/chains/base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    270\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    271\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1036\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1036\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1045\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1046\u001b[0m         )\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:844\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    842\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    845\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:833\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    830\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 833\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:457\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    456\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages/langchain/agents/mrkl/output_parser.py:52\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     48\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: text\u001b[38;5;241m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()}, text\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[1;32m     55\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[1;32m     60\u001b[0m ):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[1;32m     64\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     65\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     66\u001b[0m     )\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: ` Who won the World cup in 2022?`"
          ]
        }
      ],
      "source": [
        "llm=ChatOpenAI(openai_api_base=\"http://localhost:1234/v1\", max_tokens=5000)\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "response = agent.run(\"Take a deep breath and think about this step-by-step. Who won the World cup in 2022?\")\n",
        "# response = agent.run(\"Take a deep breath and think about this step-by-step. Who is the biggest animal is the world?\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqq83dsJDdae"
      },
      "source": [
        "**Memory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "cenJ23zKDfHT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to write a new lecture about Large Language Model, suggest a fancy name for this\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\"Demystifying the Giants: A Deep Dive into Large Language Models\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "\n",
        "prompt_template_lecture_name = PromptTemplate(\n",
        "    input_variables=[\"subject\"],\n",
        "    template=\"I want to write a new lecture about {subject}, suggest a fancy name for this\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_lecture_name, memory=memory ,verbose=True)\n",
        "response = chain.run(\"Large Language Model\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "ofYeD9YAFYvl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to write a new lecture about Pizza, suggest a fancy name for this\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\"Slices of Glory: An Ode to Pizza\"\n"
          ]
        }
      ],
      "source": [
        "response = chain.run(\"Pizza\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "bwIpujG4FZMF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to write a new lecture about Space, suggest a fancy name for this\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\"Galactic Symphony: A Journey Through the Cosmos\"\n"
          ]
        }
      ],
      "source": [
        "response = chain.run(\"Space\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "phXrvz-MFctu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: Large Language Model\n",
            "AI: \"Demystifying the Giants: A Deep Dive into Large Language Models\"\n",
            "Human: Pizza\n",
            "AI: \"Slices of Glory: An Ode to Pizza\"\n",
            "Human: Space\n",
            "AI: \"Galactic Symphony: A Journey Through the Cosmos\"\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "44p8MQqRGAyb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "gOhN3u3XFwHp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "chain2 = ConversationChain(llm=ChatOpenAI(temperature=0.7) )\n",
        "chain2.memory = ConversationBufferWindowMemory(k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "agf5PtG_GXfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The winner of the first FIFA World Cup was Uruguay.\n",
            "------------------------\n",
            "Human: Who won the first world cup?\n",
            "AI: The winner of the first FIFA World Cup was Uruguay.\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"Who won the first world cup?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "vL-YC5MPGXmR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 + 200 equals 300.\n",
            "------------------------\n",
            "Human: How much is 100 + 200?\n",
            "AI: 100 + 200 equals 300.\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"How much is 100 + 200?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "RdwXYcWeGXva"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, I do not have enough information to answer that question. Could you please provide more context?\n",
            "------------------------\n",
            "Human: What was the score of that game?\n",
            "AI: I'm sorry, I do not have enough information to answer that question. Could you please provide more context?\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"What was the score of that game?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "c0H7gzW4HSeW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=3)\n",
        "\n",
        "chain2 = ConversationChain(llm=ChatOpenAI(temperature=0.7), memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "hDy5cYScHilz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first FIFA World Cup was won by Uruguay in 1930. They defeated Argentina 4-2 in the final, which was held in Montevideo, Uruguay. Uruguay's victory in the inaugural World Cup was a significant moment in the history of football.\n",
            "------------------------\n",
            "Human: Who won the first world cup?\n",
            "AI: The first FIFA World Cup was won by Uruguay in 1930. They defeated Argentina 4-2 in the final, which was held in Montevideo, Uruguay. Uruguay's victory in the inaugural World Cup was a significant moment in the history of football.\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"Who won the first world cup?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "GlWKXlJdHjnK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 + 200 is equal to 300.\n",
            "------------------------\n",
            "Human: Who won the first world cup?\n",
            "AI: The first FIFA World Cup was won by Uruguay in 1930. They defeated Argentina 4-2 in the final, which was held in Montevideo, Uruguay. Uruguay's victory in the inaugural World Cup was a significant moment in the history of football.\n",
            "Human: How much is 100 + 200?\n",
            "AI: 100 + 200 is equal to 300.\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"How much is 100 + 200?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "chDbSlOAHkpF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The score of the first FIFA World Cup final between Uruguay and Argentina was 4-2 in favor of Uruguay.\n",
            "------------------------\n",
            "Human: Who won the first world cup?\n",
            "AI: The first FIFA World Cup was won by Uruguay in 1930. They defeated Argentina 4-2 in the final, which was held in Montevideo, Uruguay. Uruguay's victory in the inaugural World Cup was a significant moment in the history of football.\n",
            "Human: How much is 100 + 200?\n",
            "AI: 100 + 200 is equal to 300.\n",
            "Human: What was the score of that game?\n",
            "AI: The score of the first FIFA World Cup final between Uruguay and Argentina was 4-2 in favor of Uruguay.\n"
          ]
        }
      ],
      "source": [
        "print(chain2.run(\"What was the score of that game?\"))\n",
        "print (\"------------------------\")\n",
        "print (chain2.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knf6tyNWH4TL"
      },
      "source": [
        "**Doument Loaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "0sBRdxVgH8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /Users/iliagerman/Work/Sela/ai/courses/langchain_and_more/.venv/lib/python3.11/site-packages (3.15.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQwZ-_VuJDEM"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./sample_data/demo.pdf\")\n",
        "pages = loader.load();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRvWujQfJYjT"
      },
      "outputs": [],
      "source": [
        "pages[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
